# XAI
Everything about Explainable AI (XAI) (papers, books, etc.) 

[TOC]

## Contribute

If you find any errors, or you wish to add some papers, please feel free to contribute to this list by contacting me or by creating a pull request using the following Markdown format:

```
- Paper Name.
    [[pdf]](_link)
    [[code]](link)
    - Author 1, Author 2, and Author 3. *Conference Year*
    - comment
```

## Papers

- Gradient-based Uncertainty Attribution for Explainable Bayesian Deep Learning
    [[pdf]](https://arxiv.org/abs/2304.04824)
    - Hanjing Wang, Dhiraj Joshi, Shiqiang Wang, Qiang Ji. *CVPR 2023*
    - 利用贝叶斯深度学习网络解决预测模型中的不确定性问题并提供不确定性问题的归因结果，并通过实验验证了方法在准确率和时间效率上的优越性。


- Are Data-driven Explanations Robust against Out-of-distribution Data?
    [[pdf]](https://arxiv.org/abs/2303.16390)
    [[code]](https://github.com/tangli-udel/DRE)
    - Tang Li, Fengchun Qiao, Mengmeng Ma, Xi Peng. *CVPR 2023*
    - 属于一篇可解释性应用的文章，基于已有的可解释性方法，针对 OOD 场景问题，加入一些 OOD 场景下可解释性结果的相关限制作为损失函数，训练得到一个对于 OOD 问题可解释性结果更好的模型。


- IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients
    [[pdf]](https://arxiv.org/abs/2303.14242)
    [[code]](https://github.com/yangruo1226/idgi)
    - Ruo Yang, Binghui Wang, Mustafa Bilgic. *CVPR 2023*
    - 


- IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients
    [[pdf]](https://arxiv.org/abs/2303.14242)
    [[code]](https://github.com/yangruo1226/idgi)
    - Ruo Yang, Binghui Wang, Mustafa Bilgic. *CVPR 2023*
    - 

- OCTET: Object-aware Counterfactual Explanations
    [[pdf]](https://arxiv.org/abs/2211.12380)
    [[code]](https://github.com/valeoai/octet)
    - Mehdi Zemni, Mickaël Chen, Éloi Zablocki, Hédi Ben-Younes, Patrick Pérez, Matthieu Cord. *CVPR 2023*
    - 

- Don't Lie to Me! Robust and Efficient Explainability with Verified Perturbation Analysis
    [[pdf]](https://arxiv.org/abs/2202.07728)
    - Thomas Fel, Melanie Ducoffe, David Vigouroux, Remi Cadene, Mikael Capelle, Claire Nicodeme, Thomas Serre. *CVPR 2023*
    - 


- SplineCam: Exact Visualization and Characterization of Deep Network Geometry and Decision Boundaries
    [[pdf]](https://arxiv.org/abs/2302.12828)
    [[code]](https://github.com/AhmedImtiazPrio/SplineCAM)
    - Ahmed Imtiaz Humayun, Randall Balestriero, Guha Balakrishnan, Richard Baraniuk. *CVPR 2023*
    - 


- Sanity Checks for Saliency Maps.
    [[pdf]](https://arxiv.org/abs/1810.03292)
    [[code]](https://github.com/adebayoj/sanity_checks_saliency)
    - Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, and Been Kim. *NIPS 2018*
    - comment


## Codebase

- [Captum: Model interpretability and understanding for PyTorch](https://github.com/pytorch/captum)